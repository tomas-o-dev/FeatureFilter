{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "> **Essential ML process for Intrusion Detection**\n",
    "<br>` python  3.7.13    scikit-learn  1.0.2 `\n",
    "<br>`numpy   1.19.5          pandas  1.3.5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_S34U5S-i69d"
   },
   "source": [
    "**Import the main libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "\n",
    "import os\n",
    "data_path = '../datasets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9IZetEZ8jQJm"
   },
   "source": [
    "**Import the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using boosted Train and preprocessed Test\n",
    "\n",
    "data_file = os.path.join(data_path, 'NSL_ppTrain.csv') \n",
    "train_df = pandas.read_csv(data_file)\n",
    "print('Train Dataset: {} rows, {} columns'.format(train_df.shape[0], train_df.shape[1]))\n",
    "\n",
    "data_file = os.path.join(data_path, 'NSL_ppTest.csv') \n",
    "test_df = pandas.read_csv(data_file)\n",
    "print('Test Dataset: {} rows, {} columns'.format(test_df.shape[0], test_df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg"
   },
   "source": [
    "***\n",
    "**Data Preparation and EDA** (consistency checks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "* _Check column names of numeric attributes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trnn = train_df.select_dtypes(include=['float64','int64']).columns\n",
    "tstn = test_df.select_dtypes(include=['float64','int64']).columns\n",
    "trndif = numpy.setdiff1d(trnn, tstn)\n",
    "tstdif = numpy.setdiff1d(tstn, trnn)\n",
    "\n",
    "print(\"Numeric features in the train_set that are not in the test_set: \",end='')\n",
    "if len(trndif) > 0:\n",
    "    print('\\n',trndif)\n",
    "else:\n",
    "    print('None')\n",
    "\n",
    "print(\"Numeric features in the test_set that are not in the train_set: \",end='')\n",
    "if len(tstdif) > 0:\n",
    "    print('\\n',tstdif)\n",
    "else:\n",
    "    print('None')\n",
    "\n",
    "print()\n",
    "# correct any differences here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Check column names of categorical attributes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trnn = train_df.select_dtypes(include=['object']).columns\n",
    "tstn = test_df.select_dtypes(include=['object']).columns\n",
    "trndif = numpy.setdiff1d(trnn, tstn)\n",
    "tstdif = numpy.setdiff1d(tstn, trnn)\n",
    "\n",
    "print(\"Categorical features in the train_set that are not in the test_set: \",end='')\n",
    "if len(trndif) > 0:\n",
    "    print('\\n',trndif)\n",
    "else:\n",
    "    print('None')\n",
    "\n",
    "print(\"Categorical features in the test_set that are not in the train_set: \",end='')\n",
    "if len(tstdif) > 0:\n",
    "    print('\\n\\t',tstdif)\n",
    "else:\n",
    "    print('None')\n",
    "\n",
    "print()\n",
    "# correct any differences here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Drop columns with only one value_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eq_one = []\n",
    "for col in train_df.columns:\n",
    "    lctrn = len(train_df[col].unique())\n",
    "    lctst = len(test_df[col].unique())\n",
    "    if (lctrn == 1) and (lctrn == lctst): \n",
    "        n_eq_one.append(train_df[col].name)\n",
    "\n",
    "if len(n_eq_one) > 0:\n",
    "    print('Dropping single-valued features')\n",
    "    print(n_eq_one)\n",
    "    train_df.drop(n_eq_one, axis=1, inplace=True)\n",
    "    test_df.drop(n_eq_one, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Check categorical feature values:<br>\n",
    "differences will be resolved by one-hot encoding the combined test and train sets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trnn = train_df.select_dtypes(include=['object']).columns\n",
    "for col in trnn:\n",
    "    tr = train_df[col].unique()\n",
    "    ts = test_df[col].unique()\n",
    "    trd = numpy.setdiff1d(tr, ts)\n",
    "    tsd = numpy.setdiff1d(ts, tr)\n",
    "    \n",
    "    print(col,'::> ')\n",
    "    print(\"\\tUnique text values in the train_set that are not in the test_set: \",end='')\n",
    "    if len(trd) > 0:\n",
    "        print('\\n\\t',trd)\n",
    "    else:\n",
    "        print('None')\n",
    "    \n",
    "    print(\"\\tUnique text values in the test_set that are not in the train_set: \",end='')\n",
    "    if len(tsd) > 0:\n",
    "        print('\\n\\t',tsd)\n",
    "    else:\n",
    "        print('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Combine for processing classification target and text features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pandas.concat([train_df, test_df])\n",
    "print('Combined Dataset: {} rows, {} columns'.format(\n",
    "    combined_df.shape[0], combined_df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Classification Target feature:\n",
    "# two columns of labels are available \n",
    "#    * Two-class: labels     * Multiclass: atakcat\n",
    "\n",
    "# Two-class: Reduce the detailed attack labels to 'normal' or 'attack'\n",
    "labels_df = combined_df['label'].copy()\n",
    "labels_df[labels_df != 'normal'] = 'attack'\n",
    "\n",
    "# drop target features \n",
    "combined_df.drop(['label'], axis=1, inplace=True)\n",
    "combined_df.drop(['atakcat'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**QLCFF: Quick Layered Correlation-based Feature Filter**<br>\n",
    "> **_library requirements:_**<br>\n",
    "    * Dataframe with only numeric columns<br>\n",
    "    * Numeric class labels in \"array-like\" with shape (n,1)<br>\n",
    "    * Binary classification (not multiclass or multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# one-Hot encoding the remaining text features\n",
    "categori = combined_df.select_dtypes(include=['object']).columns\n",
    "category_cols = categori.tolist()\n",
    "\n",
    "features_df = pandas.get_dummies(combined_df, columns=category_cols)\n",
    "features_df.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# numeric values for the target feature\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "ynum = LabelEncoder().fit_transform(labels_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "_**import the local library**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add parent folder path where lib folder is\n",
    "import sys\n",
    "if \"..\" not in sys.path:import sys; sys.path.insert(0, '..') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## or ## from QLCFF import *\n",
    "# \n",
    "from QLCFF import mkbins\n",
    "from QLCFF import filter_fcy, filter_fdr, filter_fcc\n",
    "from QLCFF import get_filter, rpt_ycor, rpt_fcor\n",
    "\n",
    "# mkbins: applies sklearn KBinsDiscretizer(strategy='uniform', encode='ordinal') \n",
    "#       https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-discretization\n",
    "\n",
    "# filter_fcy: naive filter, feature-to-label (f2y) correlations  \n",
    "#       filter all with low correlation to target\n",
    "# filter_fdr: sklearn univariate chi-square test: FDR or FWE\n",
    "#       https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection\n",
    "# filter_fcc: FCBF-style, filter on feature-to-feature (f2f) correlations\n",
    "#       using Pearson correlation (PC) or symmetric uncertainty (SU)\n",
    "\n",
    "# get_filter: returns list of features from f2y report\n",
    "# rpt_ycor: print feature-to-label (f2y) correlations \n",
    "# rpt_fcor: print feature-to-feature (f2f) correlations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg",
    "tags": []
   },
   "source": [
    " ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**mkbins(): FDR/FWE and SU requre binning**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### def mkbins(indf, nb=20, detail=False):\n",
    "# Requires: features dataframe\n",
    "#    nb =  maximum number of bins, default 20\n",
    "#    detail = print report, boolean, default False\n",
    "# Returns: binned (discretized) dataframe\n",
    "\n",
    "# applies sklearn KBinsDiscretizer(strategy='uniform', encode='ordinal')\n",
    "# R doc for miMRMR asserts 10 bins is consistent with the literature\n",
    "# 20 bins with uniform strategy means each bin is 5% of observed values\n",
    "#   (ideally - it is really max_bins, uniform means all are the same size) \n",
    "\n",
    "tmpdf = mkbins(features_df, detail=True)\n",
    "# tmpdf.info(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg",
    "tags": []
   },
   "source": [
    " ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive filter and univariate tests both filter features\n",
    "#    on the basis that low correlation with the target labels\n",
    "#    means low utility for distinguishing class membership\n",
    "# chi_sq is a formal test for independence, fwe will select more to drop\n",
    "#    than fdr, lower threshold will select more than higher\n",
    "# naive filter will select all from either univariate test, and more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>_**filter_fcy(): naive filter**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### def filter_fcy(indf, ingt, minpc=0.1, minsu=0.01):\n",
    "# naive filter: keep if f2y_pc >= minpc or f2y_su >= minsu\n",
    "# Requires: features_df, numeric_labels\n",
    "#    minpc = threshold (alpha) for pearson correlation\n",
    "#    minsu = threshold (alpha) for symmetric uncertainty   \n",
    "# Returns: f2y report for features to drop\n",
    "\n",
    "print('\\nNaive filter (low correlation with target)')\n",
    "nfdrop_yc, nfkeep_yc = filter_fcy(tmpdf, ynum)\n",
    "\n",
    "if (len(nfdrop_yc) > 1):\n",
    "    nfdrop = get_filter(nfdrop_yc)\n",
    "    nfkeep = get_filter(nfkeep_yc)\n",
    "    \n",
    "    print('To Keep:',len(nfkeep),'features')\n",
    "#    rpt_ycor(nfkeep_yc)\n",
    "    print('To Drop:',len(nfdrop),'features')\n",
    "#    rpt_ycor(nfdrop_yc)\n",
    "else:\n",
    "    print('No features were selected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the \"keep\" filter to the real dataset\n",
    "# pandas has a lot of rules about returning a 'view' vs. a copy\n",
    "#        so we force it to create a new dataframe \n",
    "# python assigns by reference (namespaces) so keeping a reference\n",
    "#        to the original is minimal overhead\n",
    "\n",
    "# features_df_original = features_df\n",
    "filtered_df = features_df[nfkeep].copy()\n",
    "filtered_df.info(verbose=False)\n",
    "# features_df = filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>_**filter_fdr(): univariate chi_sq layer**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### def filter_fdr(dfin, gtin, t=0.01, usefdr=True):\n",
    "# Requires: features_df, numeric_labels\n",
    "#    t = threshold (alpha) for chi_sq test, sklearn default is 0.5\n",
    "#    usefdr = test, boolean, fdr if True, else fwe  \n",
    "# Returns: f2y report for features to drop\n",
    "\n",
    "# set test:\n",
    "# tst = 'FDR'\n",
    "# ufd = True\n",
    "# = or =\n",
    "tst = 'FWE'\n",
    "ufd = False\n",
    "\n",
    "print('\\nUnivariate chi-sq',tst,'test')\n",
    "uvdrop_yc = filter_fdr(tmpdf, ynum, usefdr=ufd)\n",
    "\n",
    "if (len(uvdrop_yc) > 1):\n",
    "    uvdrop = get_filter(uvdrop_yc)\n",
    "\n",
    "    print('Progressive_filtering: Dropping',len(uvdrop),'features')\n",
    "    tmpdf.drop(uvdrop, axis = 1, inplace = True)\n",
    "\n",
    "    print('\\nFiltered:',tst,'Layer')\n",
    "    rpt_ycor(uvdrop_yc)\n",
    "else:\n",
    "    uvdrop = uvdrop_yc \n",
    "    print('\\n',tst,'Layer: No features were selected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg",
    "tags": []
   },
   "source": [
    " ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCBF-Pearson and FCBF-SU Layers use the same code:  filter_fcc()\n",
    "#            metric depends on the boolean argument:  usesu\n",
    "# just use appropriate names for the return values\n",
    "#      features to keep are called \"predominant features\" in the FCBF paper; \n",
    "#      they act as proxies for the highly correlated features to drop\n",
    "#      see Lei Yu & Huan Liu, Proc. 20th ICML 2003"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>_**filter_fcc(): FCBF-SU layer**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### def filter_fcc(dfin, ingt, t=0.7, usesu=False):\n",
    "# Requires: features_df, numeric_labels\n",
    "#    t = threshold (alpha) for \"high\" f2f correlation\n",
    "#        standard for detecting multicollinearity is 0.7\n",
    "#    usesu = metric, boolean, su if True, else pearson  \n",
    "# Returns: f2y report for features to drop\n",
    "#          f2y report for features to keep\n",
    "#          f2f above threshold report \n",
    "\n",
    "sudrop_yc, sukeep_yc, su_hicorr = filter_fcc(tmpdf, ynum, usesu=True)\n",
    "\n",
    "if (len(sudrop_yc) > 1):\n",
    "    sudrop = get_filter(sudrop_yc)\n",
    "\n",
    "    print('Progressive_filtering: Dropping',len(sudrop),'features')\n",
    "    tmpdf.drop(sudrop, axis = 1, inplace = True)\n",
    "\n",
    "    print('\\nKept: FCBF (SU) Layer')\n",
    "    rpt_ycor(sukeep_yc)\n",
    "    print('\\nFiltered: FCBF (SU) Layer')\n",
    "    rpt_ycor(sudrop_yc)\n",
    "    print('\\nHighly correlated features: FCBF (SU) Layer')\n",
    "    rpt_fcor(su_hicorr)\n",
    "else:\n",
    "    sudrop = sudrop_yc \n",
    "    print('\\nFCBF (SU) Layer\\nNo features were selected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>_**filter_fcc(): FCBF-Pearson layer**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### def filter_fcc(dfin, ingt, t=0.7, usesu=False):\n",
    "# Requires: features_df, numeric_labels\n",
    "#    t = threshold (alpha) for \"high\" f2f correlation\n",
    "#        standard for detecting multicollinearity is 0.7\n",
    "#    usesu = metric, boolean, su if True, else pearson \n",
    "# Returns: f2y report for features to drop\n",
    "#          f2y report for features to keep\n",
    "#          f2f above threshold report \n",
    "\n",
    "pcdrop_yc, pckeep_yc, pc_hicorr = filter_fcc(tmpdf, ynum)\n",
    "\n",
    "if (len(pcdrop_yc) > 1):\n",
    "    pcdrop = get_filter(pcdrop_yc)\n",
    "\n",
    "    print('Progressive_filtering: Dropping',len(pcdrop),'features')\n",
    "    tmpdf.drop(pcdrop, axis = 1, inplace = True)\n",
    "\n",
    "    print('\\nKept: Pearson Layer')\n",
    "    rpt_ycor(pckeep_yc)\n",
    "    print('\\nFiltered: Pearson Layer')\n",
    "    rpt_ycor(pcdrop_yc)\n",
    "    print('\\nHighly correlated features: Pearson Layer')\n",
    "    rpt_fcor(pc_hicorr)\n",
    "else:\n",
    "    pcdrop = pcdrop_yc \n",
    "    print('\\nPearson Layer\\nNo features were selected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg",
    "tags": []
   },
   "source": [
    " ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## QLCFF: Quick Layered Correlation-based Feature Filter\n",
    "## full layered drop filter for real DF \n",
    "QLCFFilter = []\n",
    "QLCFFilter.extend(x for x in uvdrop if x not in QLCFFilter)\n",
    "QLCFFilter.extend(x for x in pcdrop if x not in QLCFFilter)\n",
    "QLCFFilter.extend(x for x in sudrop if x not in QLCFFilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the \"drop\" filter to the real dataset\n",
    "\n",
    "# features_df_original = features_df\n",
    "filtered_df = features_df.drop(QLCFFilter, axis = 1)\n",
    "filtered_df.info(verbose=False)\n",
    "# features_df = filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg",
    "tags": []
   },
   "source": [
    " ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
